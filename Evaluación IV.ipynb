{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnTkIpP6ECAE5X+zk7bumm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MontseCan/iTecBooks/blob/main/Evaluaci%C3%B3n%20IV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcC9hPxLT6cw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><center>INTRODUCCIÓN</center></h1>\n",
        "\n",
        "Python es un lenguaje de programación que destaca por su versatilidad y funcionalidad. Además de ser de código abierto, Python es interactivo y multiplataforma.\n",
        "\n",
        "Entre sus características principales, cabe destacar que dispone de fuentes incorporadas, así como de diferentes tipos de librerías.\n",
        "\n",
        "Las librerías de Python son una herramienta fundamental para consolidar la formación de todo programador web. ¿Sabías que los programas desarrollados con Python son los más importantes en el mundo digital? Así es, Python es uno de los lenguajes de programación más usados del momento y muchas empresas necesitan contar con él. \n",
        "\n",
        "Según David Zarruk, profesor del curso de analítica predictiva y modelos de regresión en Python, una librería de programación es un conjunto de funciones que alguien escribió en alguna parte del mundo y ha disponibilizado para que cualquiera pueda utilizarlo de forma gratuita. \n",
        "\n",
        "Entonces, ¿qué es una librería en Python? Este concepto hace referencia al conjunto de implementos funcionales que te ayudarán a codificar todo este lenguaje de programación para crear una interfaz independiente. \n",
        "\n",
        "Las librerías de Python son amplias y cuentan con gran cantidad de producciones en contenidos. Constan de diversos módulos que permiten el acceso de funcionalidades específicas del sistema como entrada y salida de archivos, soluciones estandarizadas a problemas de programación, etc.\n",
        "\n",
        "Además, dependiendo del sistema operativo que tengas, puedes conseguir diferentes funciones de cada una de las librerías de Python. Por ejemplo, para el sistema Windows se incluye la biblioteca estándar completa junto con componentes adicionales.\n",
        "Un plus para las librerías de Python es que cuentan con una colección de componentes como, por ejemplo, programas individuales, módulos, paquetes, frameworks, aplicaciones y más funciones que puedes encontrar en Python Package Index.\n",
        "\n",
        "<h1><center>PROCESAMIENTO DE DATOS MASIVOS</center></h1>\n",
        "\n",
        "<h2>¿Qué es el procesamiento de datos?</h2>\n",
        "\n",
        "Para dar valor a este conjunto de datos almacenados en la red, ha surgido el procesamiento de datos, cuya misión es manejar grandes cantidades de datos y transformarlos en información valiosa para la toma de decisiones gerenciales.\n",
        "\n",
        "En Wikipedia se define el procesamiento de datos como “la acumulación y manipulación de elementos de datos para producir información significativa”.\n",
        "\n",
        "Dónde se almacena dicha información es un interrogante muy común y para dar respuesta a ello nace el término Big data. También llamado macrodatos o datos masivos, Big data es un término que hace referencia al proceso que abarca la recolección de grandes cantidades de datos y su inmediato análisis.\n",
        "\n",
        "Debido a su magnitud, este proceso supera la capacidad de un software convencional para capturarlos, administrarlos y procesarlos en un tiempo razonable. Es por esta razón que nace la necesidad de nuevos canales de procesamiento de información que haga más viable la captura y análisis de tan cantidad de datos.\n",
        "\n",
        "¿Sabías que el Big Data creció a una velocidad nunca antes vista? Ya para el año 2020 se estimaba que cada individuo podía crear 1,7 megabytes de información por segundo. Esas cifras siguieron y seguirán creciendo aún más. Hay quienes dicen que el internet es otro mundo y parecen tener razón si se toma en cuenta la enorme cantidad de información que alberga acerca de nuestras acciones diarias y los numerosos datos que maneja.\n",
        "\n",
        "De alguna manera, el Big Data es el futuro de los negocios.\n",
        "\n",
        "<h2>¿Cómo se conforma el Big Data?</h2>\n",
        "\n",
        "El Big Data se ve representado por 5 V que logran describir su funcionamiento y características:<br>\n",
        "\n",
        "<h3>Volumen</h3>\n",
        "Esta es quizás la característica más representativa del Big Data: los grandes volúmenes de información que se manejan a diario en el internet.\n",
        "\n",
        "Captar y analizar estos datos es esencial para muchas de las empresas de la actualidad.\n",
        "\n",
        "<h3>Velocidad</h3>\n",
        "El Big Data permite acceder de manera inmediata a la información recopilada en el internet, la que puede ser usada con el fin de extraerle valor de negocio.\n",
        "\n",
        "<h3>Variedad</h3>\n",
        "Una fortaleza del Big Data es combinar datos para alcanzar un todo homogéneo y obtener información relevante a partir de esto.\n",
        "\n",
        "<h3>Valor</h3>\n",
        "Sin duda alguna, los datos que se generan a diario en el internet y su respectivo procesamiento son de gran importancia no solo para empresas, sino también para gobiernos y la sociedad en general.\n",
        "\n",
        "<h3>Veracidad</h3>\n",
        "En un mundo donde se generan 2.5 quintillones de bytes de datos a diario, es de vital importancia identificar la veracidad de estos para extraer valor a partir de ellos.\n",
        "\n",
        "<h2>¿Cómo se lleva a cabo el procesamiento de datos?</h2>\n",
        "\n",
        "<h3>1. Recopilación</h3>\n",
        "Claro está que el primer paso es colectar los datos. Estos se obtienen de diferentes fuentes, tales como archivos de texto o almacenes de imágenes.\n",
        "\n",
        "<h3>2. Preparación de los datos</h3>\n",
        "Esta etapa también es conocida como preprocesamientoy tiene que ver con la limpieza y organización de los datos recopilados pero aún no procesados.\n",
        "\n",
        "El objetivo aquí es eliminar aquello que no sirva o sea innecesario.\n",
        "\n",
        "<h3>3. Entrada de datos</h3>\n",
        "Una vez los datos están limpios y organizados, ingresan en su destino y se traducen a un idioma comprensible.\n",
        "\n",
        "<h3>4. Procesamiento</h3>\n",
        "Puede realizarse a través de técnicas de filtrado, análisis, visualización o algoritmos de aprendizaje automático. De todos modos, esto puede variar dependiendo de la fuente de datos a procesar.\n",
        "\n",
        "<h3>5. Interpretación</h3>\n",
        "En esta etapa los datos ya están listos para ser interpretados y usados. Aquí, la empresa puede comenzar a administrarlos para sus propios proyectos.\n",
        "\n",
        "<h3>6. Almacenamiento</h3>\n",
        "Los datos pueden ser almacenados para su uso futuro. Al quedar al alcance de los miembros de la empresa, se puede acceder cuando sea necesario.\n",
        "\n",
        "<h2>¿Qué tipos de procesamiento de datos hay?</h2>\n",
        "\n",
        "Existen varias formas de procesar los datos. Estas son:\n",
        "\n",
        "<h3>1. Proceso manual</h3>\n",
        "Esta es la forma más antigua de hacerlo y se basa en el trabajo del personal humano para registrar, ordenar y clasificar datos de forma escrita. Claramente, este proceso es muy lento y, además, es susceptible de tener grandes márgenes de error.\n",
        "\n",
        "<h3>2. Proceso mecánico</h3>\n",
        "Se caracteriza por utilizar máquinas registradoras y calculadoras, lo cual sustituye el cálculo manual en rapidez y confiabilidad.\n",
        "\n",
        "<h3>3. Proceso electromecánico</h3>\n",
        "Aunque la información, comunicación y almacenamiento siguen manipulándose manualmente, al menos una de las actividades se ve cubierta por una máquina.\n",
        "\n",
        "<h3>4. Procesos electrónicos</h3>\n",
        "Este es el proceso más moderno y en el cual la participación humana es prescindible. Una vez capturados los datos, la computadora es capaz de realizar los procesos necesarios por sí sola si está previamente configurada para ello.\n",
        "\n",
        "Este método es muchísimo más rápido y presenta un margen de error casi nulo.\n",
        "\n",
        "<h1><center>MODELOS Y HERRAMIENTAS DE PROCESAMIENTO DE DATOS MASIVOS</center></h1>\n",
        "\n",
        "Uno de los objetivos del uso de las tecnologías Big Data es el de transformar los datos en conocimiento útil para la empresa, y para ello se necesitan herramientas Big Data que nos ayuden a analizar, procesar y almacenar todos los datos recogidos. Un gran número de entre las mejores herramientas usadas en Big Data son open source, lo que da fe del éxito de este modelo de desarrollo, además de las alternativas de pago.\n",
        "\n",
        "A continuación te mostramos una selección de herramientas open source que ofrecen soluciones para la explotación de software de Big Data en todos sus procesos: almacenamiento, procesamiento y análisis, que seguramente te serán útiles en tus proyectos.\n",
        "\n",
        "<h3>1. Hadoop</h3>\n",
        "\n",
        "No se puede hablar de Big Data sin hablar de la veterana Apache Hadoop. Esta herramienta Big Data open source se considera el framework estándar para el almacenamiento de grandes volúmenes de datos; se usa también para analizar y procesar, y es utilizado por empresas como Facebook y Yahoo!.\n",
        "\n",
        "La biblioteca Hadoop utiliza modelos de programación simples para el almacenamiento y procesamiento distribuido de grandes conjuntos de datos en clusters, dando redundancia para no perder nada y, al mismo tiempo, aprovechando muchos procesos a la vez.\n",
        "\n",
        "Dispone de un sistema de archivos distribuido en cada nodo del cluster: el HDFS (Hadoop Distributed File System), y se basa en el proceso de MapReduce de dos fases.\n",
        "\n",
        "Soporta diferentes sistemas operativos y también se usa frecuentemente sobre cualquiera de las principales plataformas en la nube, como Amazon EC2/S3 o Google Cloud.\n",
        "\n",
        "<h3>2. MongoDB</h3>\n",
        "\n",
        "Dentro de las bases de datos NoSQL, probablemente una de las más famosas sea MongoDB. Con un concepto muy diferente al de las bases de datos relacionales, se está convirtiendo en una interesante alternativa para almacenar los datos de nuestras aplicaciones.\n",
        "\n",
        "MongoDB es una base de datos orientada a documentos (guarda los datos en documentos, no en registros). Estos documentos son almacenados en BSON, que es una representación binaria de JSON.\n",
        "\n",
        "A pesar de que las bases de datos NoSQL no tienen una extensa variedad de uso, MongoDB tiene un ámbito de aplicación más amplio en diferentes tipos de proyectos: es especialmente útil en entornos que requieran escalabilidad. Con sus opciones de replicación y sharding, podemos conseguir un sistema que escale horizontalmente sin demasiados problemas.\n",
        "\n",
        "<h3>3. Elasticsearch</h3>\n",
        "\n",
        "Elasticsearch es una potente herramienta para la búsqueda entre grandes cantidades de datos, especialmente cuando los datos son de tipo complejo.\n",
        "\n",
        "Nos permite indexar y analizar en tiempo real un gran volumen de datos y hacer consultas sobre ellos. Un ejemplo de uso son las consultas de texto completo; al estar los datos indexados, los resultados se obtienen de forma muy rápida. En el IIC utilizamos esta herramienta para indexar datos dentro de nuestras soluciones de entorno digital.\n",
        "\n",
        "A diferencia de otros sistemas parecidos, no necesita declarar un esquema de la información que añadimos, no sabemos exactamente qué forma van a tener los datos.\n",
        "\n",
        "Con Elasticsearch podemos hacer búsquedas de texto complicadas, visualizar el estado de nuestros nodos y escalar sin demasiadas necesidades, si se diera el caso de que necesitáramos más potencia.\n",
        "\n",
        "<h3>4. Apache Spark</h3>\n",
        "\n",
        "Apache Spark es un motor de procesamiento de datos de código abierto realmente rápido.\n",
        "\n",
        "Creado por Matei Zaharia en la Universidad de Berkeley, se considera el primer software open source que hace la programación distribuida (muy en esencia, consiste en distribuir el trabajo entre un grupo de ordenadores, “cluster”, que trabajan como uno) realmente accesible a los científicos de datos.\n",
        "\n",
        "Se pueden programar aplicaciones usando diferentes lenguajes como Java, Scala, Python o R. pudiendo ser, según el programa, hasta 100 veces más rápido en memoria o 10 veces más en disco que Hadoop MapReduce.\n",
        "\n",
        "<h3>5. Apache Storm</h3>\n",
        "\n",
        "Apache Storm es un sistema de computación distribuida en tiempo real orientado a procesar flujos constantes de datos, por ejemplo, datos de sensores que se emiten con una alta frecuencia o datos que provengan de las redes sociales, donde a veces es importante saber qué se está compartiendo en este momento.\n",
        "\n",
        "Aunque Hadoop sea un gran sistema para el procesado de un gran volumen de datos, no está pensado para hacerlo en tiempo real, ya que tiene una alta latencia. Apache Storm está siendo una revolución para procesar grandes cantidades de información en tiempo real, ya que es capaz de procesar millones de mensajes por segundo. En el IIC utilizamos Apache Storm para nuestra herramienta Lynguo, que requiere esta tecnología Big Data para procesar en tiempo real los comentarios de las redes sociales para su monitorización y análisis.\n",
        "\n",
        "Apache Storm puede ser utilizado para procesar los logs de nuestras aplicaciones para ver el uso que se hace de los distintos servicios y gestión de errores; para extraer información de redes sociales a través de sus APIs y analizar un fenómeno en tiempo real; recoger y procesar datos de sensores; buscadores verticales, web analytics, etc.\n",
        "\n",
        "<h3>6. Lenguaje R</h3>\n",
        "\n",
        "R es un lenguaje de programación y entorno de software para cálculo estadístico y gráficos. El lenguaje R es de los más usados por los estadistas y otros profesionales interesados en la minería de datos, la investigación  bioinformática y las matemáticas financieras.\n",
        "\n",
        "R se parece más al lenguaje de las matemáticas que a otros lenguajes de programación, lo que puede ser un inconveniente para los programadores a la hora de elegir programar en R para temas de Big Data. Lo que está claro es que si eliges usar R podrás disponer de una gran cantidad de librerías creadas por la comunidad de R y otras tantas herramientas de altísima calidad (por ejemplo, RStudio).\n",
        "\n",
        "<h3>7. Python</h3>\n",
        "\n",
        "Python es un lenguaje avanzado de programación con la ventaja de ser relativamente fácil de usar para usuarios que no estén familiarizados con la informática de manera profesional, pero que necesitan trabajar con análisis de datos (estadistas, biólogos, físicos, lingüistas…).\n",
        "\n",
        "Es una herramienta para Big Data muy eficiente, en parte debido a la gran comunidad existente, por lo que Python dispone de muchas librerías ya hechas por otros usuarios.\n",
        "\n",
        "Sin embargo, tiene en su contra que no es un lenguaje muy rápido en su ejecución, por lo que suele ser empleado para tareas de integración o tareas donde no haya cálculos pesados. \n",
        "\n",
        "<h1><center>ANÁLISIS PREDICTIVO</center></h1>\n",
        "\n",
        "<h2>¿Qué es el análisis predictivo?</h2>\n",
        "\n",
        "Mediante el uso del historial de datos, algoritmos estadísticos, modelos predictivos y técnicas de aprendizaje automático a partir de Big Data, el análisis predictivo ayuda a las organizaciones a predecir resultados de forma más precisa, a planificar de cara a acontecimientos desconocidos y a identificar oportunidades en las actividades futuras.\n",
        "\n",
        "Al tratarse de una rama de la ciencia de datos para empresas, el crecimiento del análisis predictivo y ampliado está vinculado al de los sistemas de Big Data, pues gracias a sus conjuntos de datos, más amplios y completos, se pueden incrementar las operaciones de minería de datos para extraer información predictiva valiosa. Asimismo, los avances en el aprendizaje automático a partir de Big Data han contribuido a ampliar las capacidades del análisis predictivo. \n",
        "\n",
        "<h2>¿Para qué se usa el análisis predictivo?</h2>\n",
        "\n",
        "El análisis predictivo se puede utilizar para optimizar las operaciones, aumentar los ingresos y mitigar los riesgos de casi cualquier tipo de empresa o sector, ya sea la banca, el comercio minorista, los servicios públicos, el sector público, la sanidad o el sector de la fabricación. A veces se realizan análisis ampliados mediante el uso de aprendizaje automático a partir de Big Data. A continuación, se muestran algunos ejemplos de casos prácticos, como los análisis de lagos de datos.\n",
        "\n",
        "<h3>Detección de fraudes</h3>\n",
        "Los análisis predictivos examinan todas las acciones de la red de una empresa en tiempo real para detectar anomalías que indican fraudes y otras vulnerabilidades.\n",
        "\n",
        "<h3>Optimización de operaciones</h3>\n",
        "Las empresas utilizan modelos de análisis predictivo para prever el inventario, gestionar recursos y operar de forma más eficiente. \n",
        "\n",
        "<h3>Segmentación de clientes</h3>\n",
        "Al dividir una base de clientes en grupos específicos, los profesionales del marketing pueden usar el análisis predictivo para tomar decisiones con vistas al futuro que permiten adaptar el contenido a audiencias únicas.\n",
        "\n",
        "<h3>Predicción de conversiones y compras</h3>\n",
        "Las empresas pueden tomar medidas, como el retargeting de anuncios online, a partir de datos que predicen una mayor probabilidad de conversión y de intención de compra.\n",
        "\n",
        "<h3>Reducción de riesgos</h3>\n",
        "La capacidad crediticia, las reclamaciones de seguros y los cobros de deudas se basan en el análisis predictivo, mediante el que se evalúa y se determina la probabilidad de impago en el futuro.\n",
        "\n",
        "<h3>Mantenimiento predictivo</h3>\n",
        "Las organizaciones utilizan datos para predecir cuándo se debería realizar el mantenimiento rutinario del equipo. Así, pueden programarlo antes de que ocurra algún problema o haya algún fallo en el funcionamiento.\n",
        "\n",
        "<h1><center>MAP REDUCE</center></h1>\n",
        "\n",
        "<h2>¿Qué es MapReduce?</h2>\n",
        "\n",
        "Anteriormente, en los sistemas tradicionales, las tecnologías se han enfocado en traer los datos a los sistemas de almacenamiento. Sin embargo, en los procesos Hadoop, se trata de acercar el procesamiento al lugar en donde se encuentran almacenados los datos y así aprovechar técnicas de paralelización, aumentando de manera importante la escalabilidad y el rendimiento de los sistemas que trabajan con grandes cantidades de datos.\n",
        "\n",
        "Hadoop MapReduce es un paradigma de procesamiento de datos caracterizado por dividirse en dos fases o pasos diferenciados: Map y Reduce. Estos subprocesos asociados a la tarea se ejecutan de manera distribuida, en diferentes nodos de procesamiento o esclavos. Para controlar y gestionar su ejecución, existe un proceso Master o Job Tracker. También es el encargado de aceptar los nuevos trabajos enviados al sistema por los clientes.\n",
        "\n",
        "Este sistema de procesamiento se apoya en tecnologías de almacenamiento de datos distribuidas, en cuyos nodos se ejecutan estas operaciones de tipo map y reduce. El sistema de ficheros distribuido de Hadoop es HDFS (Hadoop Distributed File System), encargado de almacenar los ficheros divididos en bloques de datos. HDFS proporciona la división previa de los datos en bloques que necesita MapReduce para ejecutar. Los resultados del procesamiento se pueden almacenar en el mismo sistema de almacenamiento o bien en una base de datos o sistema externo.\n",
        "\n",
        "<img \tsrc=\"https://aprenderbigdata.com/wp-content/uploads/MapReduce-esquema-1024x615.png.webp\"/>\n",
        "\n",
        "<h2>Fases en Hadoop MapReduce</h2>\n",
        "\n",
        "En un trabajo Hadoop MapReduce, se dividen los datos de entrada en fragmentos independientes que son procesados por los mappers en paralelo. A continuación, se ordenan los resultados del map, que son la entrada para los reducers.\n",
        "\n",
        "Generalmente, las entradas y salidas de los trabajos se almacenan en un sistema de ficheros, siendo los nodos de almacenamiento y de cómputo los mismos. \n",
        "\n",
        "También es muy común que la lógica de la aplicación no se pueda descomponer en una única ejecución de MapReduce, por lo que se encadenan varias de estas fases, tratando los resultados de una como entrada para los mappers de la siguiente fase.\n",
        "\n",
        "Esta característica, permite ejecutar las tareas de cada fragmento en el nodo donde se almacena, reduciendo el tiempo de acceso a los datos y los movimientos entre nodos del clúster.\n",
        "\n",
        "El framework también se encarga de gestionar los recursos, planificar, reiniciar y monitorizar las tareas con el gestor de Hadoop YARN, que tiene un único Resource Manager y un Node Manager en cada nodo del clúster.\n",
        "\n",
        "La fase Map se ejecuta en subtareas llamadas mappers. Estos componentes son los responsables de generar pares clave-valor filtrando, agrupando, ordenando o transformando los datos originales. Los pares de datos intermedios, no se almacenan en HDFS.\n",
        "\n",
        "La fase Shuffle (sort) puede no ser necesaria. Es el paso intermedio entre Map y reduce que ayuda a recoger los datos y ordenarlos de manera conveniente para el procesamiento. Con esta fase, se pretende agregar las ocurrencias repetidas en cada uno de los mappers.\n",
        "\n",
        "La fase Reduce gestiona la agregación de los valores producidos por todos los mappers del sistema (o por la fase shuffle) de tipo clave-valor en función de su clave. Por último, cada reducer genera su fichero de salida de forma independiente, generalmente escrito en HDFS.\n",
        "\n",
        "<h2>Limitaciones en Hadoop MapReduce</h2>\n",
        "\n",
        "MapReduce es la implementación básica de un framework de procesamiento en paralelo para cargas big data. Sin embargo, tiene ciertas limitaciones que otras tecnologías intentan mejorar.\n",
        "\n",
        "En MapReduce, hasta que la fase map completa su procesamiento, los reducers no empiezan a ejecutar. Tampoco se puede controlar su orden de ejecución. Entre las alternativas, se encuentran Apache Spark, Apache Hive o Pig. Aunque las ideas principales se mantienen respecto a MapReduce, son capaces de usar HDFS de manera más eficiente para determinados tipos de trabajos. Por lo tanto, debemos conocer estas tecnologías y ser capaces de seleccionar la más adecuada para nuestro caso.\n",
        "\n",
        "<h1><center>PREPARACIÓN E INTEGRACIÓN DE DATOS</center></h1>\n",
        "\n",
        "<h2>¿Qué es la integración de datos?</h2>\n",
        "\n",
        "Los macrodatos, la Internet de las cosas (IoT), el software como servicio (SaaS), la actividad en la nube y muchas más herramientas están generando un auge en la cantidad tanto de fuentes de datos como de datos existentes en el mundo. La mayoría de estos datos ya se recopilaron y almacenaron en entornos aislados o almacenes de datos independientes. La integración de datos es el proceso que reúne esos datos para generar un mayor valor de datos y estadísticas. \n",
        "\n",
        "La integración de datos es muy importante si tu empresa desea aplicar estrategias de transformación digital, ya que la capacidad de mejorar operaciones, aumentar la satisfacción del cliente y competir en un mundo que cada día es más digital dependerá de las estadísticas que se generen a partir de todos tus datos.\n",
        "\n",
        "La solución de integración de datos de Google Cloud es Cloud Data Fusion, un servicio de integración de datos nativo de la nube completamente administrado que ayuda a los usuarios a compilar y administrar de manera eficaz canalizaciones de datos ETL/ELT.\n",
        "\n",
        "<h2>¿Cuáles son los desafíos de la integración de datos?</h2>\n",
        "\n",
        "<h3>La dificultad de usar plataformas de integración de datos</h3>\n",
        "Es difícil y costoso encontrar profesionales de datos con experiencia, pero, en general, son necesarios para implementar la mayoría de las plataformas de integración de datos. Los analistas de negocios que necesitan acceder a los datos para tomar decisiones suelen depender de estos expertos, lo que ralentiza el tiempo de generación de valor de las estadísticas de datos.\n",
        "\n",
        "<h3>Gastos altos operativos y de capital de la infraestructura de integración de datos</h3>\n",
        "Los gastos operativos y de capital aumentan cuando se procura, implementa, conserva y administra la infraestructura necesaria para una iniciativa de integración de datos de nivel empresarial. La integración de datos basada en la nube como un servicio administrado puede solucionar este problema de costos directamente.\n",
        "\n",
        "<h3>Datos estrechamente vinculados con aplicaciones</h3>\n",
        "Antes, los datos estaban tan vinculados a aplicaciones específicas (y, también, dependían de ellas) que no era posible recuperarlos y usarlos en otro sector de tu empresa. Hoy en día, se puede observar cómo se desvinculan las capas de las aplicaciones y de los datos, de modo que puedes usar tus datos de forma más flexible.\n",
        "\n",
        "<h3>Problemas de semántica de datos</h3>\n",
        "Es posible organizar varias versiones de datos que significan lo mismo o darles formato de forma distinta. Por ejemplo, las fechas se pueden almacenar de forma numérica como dd/mm/aa o como mes, día, año. El elemento de “transformación” de ETL y las herramientas de administración de datos maestros abordan este desafío.\n",
        "\n",
        "<h2>¿Cuáles son las herramientas de integración de datos?</h2>\n",
        "\n",
        "En general, las plataformas de integración de datos incluyen muchas de las siguientes herramientas:\n",
        "\n",
        "+ Herramientas de transferencia de datos: Te permiten obtener datos e importarlos para usarlos de inmediato o más adelante.\n",
        "\n",
        "+ Herramientas de ETL: ETL significa extracción, transformación y carga, el método de integración de datos más común.\n",
        "\n",
        "+ Catálogos de datos: Ayudan a los negocios a encontrar recursos de datos que se encuentran en varios sistemas aislados de datos y a hacer un inventario de ellos.\n",
        "\n",
        "+ Herramientas de administración de datos: Garantizan la disponibilidad, seguridad, integridad y usabilidad de los datos.\n",
        "\n",
        "+ Herramientas de limpieza de datos: Ayudan a limpiar datos sucios. Para ello, los reemplazan, modifican o borran.\n",
        "\n",
        "+ Herramientas de migración de datos: Trasladan datos entre computadoras, sistemas de almacenamiento o formatos de aplicación.\n",
        "\n",
        "+ Herramientas de administración de datos maestros: Ayudan a los negocios a cumplir con definiciones de datos comunes y a alcanzar una sola fuente de verdad.\n",
        "\n",
        "+ Conectores de datos: Estas herramientas trasladan datos de una base de datos a otra y, además, realizan transformaciones.\n",
        "\n",
        "<h2>¿Para qué se usa la integración de datos?</h2>\n",
        "\n",
        "La integración de datos suele usarse para lo siguiente:\n",
        "\n",
        "<h3>Desarrollo de data lakes</h3>\n",
        "Mediante la integración de datos, se trasladan datos desde plataformas locales aisladas hacia data lakes para aumentar el valor de los datos.\n",
        "\n",
        "<h3>Almacenamiento de datos</h3>\n",
        "La integración de datos reúne información de distintas fuentes en un almacén de datos a fin de analizarlos para fines comerciales. \n",
        "\n",
        "<h3>Marketing</h3>\n",
        "Mediante la integración de datos, se trasladan datos de marketing (como la información demográfica del cliente, las redes sociales y las estadísticas web) en un solo lugar para analizarlos y realizar acciones.\n",
        "\n",
        "<h3>IoT</h3>\n",
        "La integración de datos ayuda a recopilar datos de varias fuentes de IoT en un solo lugar a fin de obtener valor de ellos.\n",
        "\n",
        "<h3>Replicación de bases de datos</h3>\n",
        "La integración de datos es una parte crucial de la replicación de datos de una base de datos de origen, como Oracle, MongoDB o MySQL, a un almacén de datos en la nube.\n",
        "\n",
        "<h1><center>ALMACENAMIENTO DISTRIBUIDO</center></h1>\n",
        "\n",
        "<h2>¿Qué es el almacenamiento distribuido? ¿por qué es tan importante?</h2>\n",
        "\n",
        "Se denomina almacenamiento distribuido al uso de una red informática para almacenar datos, donde estos se guardan en más de un nodo o servidor. Este sistema permite una mayor flexibilidad, y un mejor rendimiento a la hora de manejar y acceder a los datos seleccionados, al mismo tiempo que incrementa la seguridad de la información.\n",
        "\n",
        "Las principales características de este sistema de almacenamiento de datos son:\n",
        "\n",
        "+ Flexible y Escalable. El almacenamiento distribuido se adapta a las necesidades en cada momento, pudiendo incrementarse de forma rápida y sencilla la capacidad de almacenamiento siempre que las circunstancias lo demanden. Su capacidad de escalar horizontalmente permite crear un sistema de almacenamiento compartido formado por numerosos nodos.\n",
        "\n",
        "+ Seguro. La información y el acceso a la misma está asegurada al contar con múltiples servidores replicados, por lo que si se cae uno otro pasará de forma inmediata a ocupar su lugar, sin pérdida de datos y manteniendo el acceso a los mismos.\n",
        "\n",
        "+ Rápido y eficiente. Este tipo de almacenamiento permite una gestión ágil de la información con acceso rápido para consultas, cambios, subida de datos, etc. El almacenamiento distribuido puede lograr un gran rendimiento con unos bajos requisitos de hardware al sacar el máximo partido de todos los recursos de los servidores.\n",
        "\n",
        "<h2>Ventajas del almacenamiento distribuido</h2>\n",
        "\n",
        "Los principales beneficios que aporta el almacenamiento distribuido son:\n",
        "\n",
        "+ Flexibilidad y escalabilidad. Este sistema de almacenamiento permite que un servidor estándar ejecute almacenamiento entre otro tipo de aplicaciones, pudiendo agregar más servidores para aumentar la capacidad de almacenamiento de forma lineal. Se trata de un sistema diseñado para tolerar fallas, donde cualquier incidente no es de emergencia, ya que puede ser solventado de forma automatizada.\n",
        "\n",
        "+ Mayor rendimiento. En sistema de almacenamiento distribuido cualquier servidor dispone de su propia CPU, memoria e interfaz de red, comportándose como un grupo. Cada vez que se añade un nuevo servidor el conjunto total de recursos aumenta, mejorando la velocidad y el rendimiento.\n",
        "\n",
        "+ Menor coste. Este tipo de sistemas une el almacenamiento con la computación incrementando el uso de los servidores, lo que repercute en una disminución de coste de los centros de datos en aspectos como la energía consumida, refrigeración o espacio necesario, entre otros.\n",
        "\n",
        "+ Ofrece tres tipos de almacenamiento distribuido. Se trata de un sistema unificado que ofrece almacenamiento por bloques, por ficheros y por objetos.\n",
        "\n",
        "<h2>Tipos de almacenamiento distribuido</h2>\n",
        "\n",
        "Existen distintos tipos de sistemas de almacenamiento distribuidos que permiten crear sistemas independientes y descentralizados. Algunos de los sistemas más utilizados son:\n",
        "\n",
        "<h3>Sistema IPFS</h3>\n",
        "Este sistema tiene como objetivo conectar todos los dispositivos en un único sistema de archivos distribuido basado en un protocolo peer-to-peer (p2p). De forma similar a como funciona BitTorrent permite que los usuarios realicen búsquedas en la red según el contenido de los datos (no por la ubicación de las mismas) y aparte actúen como hosts almacenando datos de terceros. Para ello utiliza tecnologías como HST y sistemas de gestión de versiones como Git.\n",
        "\n",
        "<h3>Sistema RAID</h3>\n",
        "Este sistema de almacenamiento utiliza múltiples unidades de discos duros en las cuales se distribuye y replica la información. Existen distintos tipos de sistemas Raid, como el Raid 0 para mejorar el rendimiento, el raid 1 o modo espejo para reflejar de forma idéntica los datos en distintos discos, o en Raid 10 que combina ambos tipos de Raid.\n",
        "\n",
        "<h3>Sistema GlusterFS</h3>\n",
        "Es un sistema de archivos para NAS que permite agregar varios servidores de archivos sobre una red Ethernet o un gran entorno de archivos de red en paralelo. GlusterFS se desarrolla bajo el sistema de licencia GNU por lo que es gratuito y puede utilizarse utilizando tanto servidores físicos como virtualizados.\n",
        "\n",
        "<h1><center>TECNOLOGÍAS DE ALMACENAMIENTO</center></h1>\n",
        "\n",
        "<h2>NAS, DAS y SAN, ¿Qué son y en que se diferencian?</h2>\n",
        "\n",
        "Seguro que a muchos de nosotros nos suena que es un NAS, Pero nos perdemos en el momento que hablamos de DAS y SAN.\n",
        "\n",
        "Lo mas probable es que a estas alturas ya habléis imaginado que tanto el NAS, DAS y el SAN. Son tipos tecnología de almacenamiento utilizados en servidores. Pero ¿en que se diferencian y para qué sirve cada uno? \n",
        "\n",
        "<h2>NAS (Network attached storage)</h2>\n",
        "\n",
        "La forma más sencilla de describir un NAS es definirlo como un disco duro conectado directamente a una red LAN.\n",
        "\n",
        "Por lo que estos discos duros conectados a nuestra red LAN nos permite trabajar con la información que tiene guardada en él. Dando a todos los usuarios que están conectados a esta red LAN, el poder de compartir archivos y trabajar sobre ellos.\n",
        "\n",
        "Por lo que los sistemas NAS están orientados a manejar un gran conjunto de pequeños documentos y podemos deducir que son perfectos compañeros de oficina o domésticos. Tiene las ventajas de que es de tamaño reducido y no requiere de un mantenimiento como los servidores. Además de que tiene un menor consumo eléctrico, compatible con la mayoría de sistemas operativos y es más sencillo de administrar.\n",
        "\n",
        "Algunos de sus usos pueden ser:\n",
        "\n",
        "+ Copias de seguridad.\n",
        "+ Un sistema Cloud privado.\n",
        "+ Compartir archivos\n",
        "+ Servidores Web (aunque de baja potencia)\n",
        "\n",
        "<h2>DAS (Direct Attached Storage)</h2>\n",
        "\n",
        "La principal diferencia entre un DAS y un NAS es que los primeros no disponen de funcionalidades Webs. Se podría decir que el sistema DAS es el más sencillo de los tres y prácticamente todos lo hemos usado sin saberlo. Consiste en una conexión directa del ordenador a los datos, en lugar de conectarlo con un router o NAS. Por lo que podemos decir que son discos duros externos que tienen la función de compartir los datos entre los usuarios.\n",
        "\n",
        "<h3>Ventajas:</h3>\n",
        "\n",
        "+ Mayor velocidad de acceso y transmisión de información.\n",
        "+ Mas sencillo y menos costoso que un NAS\n",
        "+ Desventajas no sirve de como servidor web\n",
        "\n",
        "\n",
        "<h2>SAN (Storage área network)</h2>\n",
        "\n",
        "Un SAN es un conjunto de dispositivos junto con un software especializado para crear una red enfocada al intercambio de datos mediante bloques. Es una tecnología perfecta para conectar servidores.\n",
        "Estos sistemas contienen red de alta velocidad, equipos de interconexión como switches y conmutadores, discos duros donde almacenar los datos\n",
        "\n",
        "<h3>Las ventajas son notables:</h3>\n",
        "\n",
        "+ Una mayor eficiencia\n",
        "+ Mayor protección para tus sistemas y datos\n",
        "+ Gran escalabilidad\n",
        "+ Encriptación\n",
        "+ Backup\n",
        "+ Su capacidad es casi ilimitada y puede alcanzar miles de terabytes de capacidad\n",
        "+ Compartir datos entre varios equipos de la red sin afectar el rendimiento ya que el tráfico SAN está separado del tráfico del usuario.\n",
        "\n",
        "En contraposición a este sistema tenemos que mencionar que es una forma de gestionar los datos muy profesional y costosa debido a la gran cantidad de hardware y personal especializado para gestionarlo.\n",
        "\n",
        "<h2>¿Qué tecnología de almacenamiento deberíamos elegir?</h2>\n",
        "\n",
        "En función de tus necesidades deberías decantarte por un sistema u otro.\n",
        "Por un lado, un DAS limita mucho el crecimiento posterior\n",
        "\n",
        "Los NAS son sencillos y fáciles de manejar. Son versátiles y simples en la puesta a punto, aunque pueden tener taras en cuestión del rendimiento en función de para que se usen y por último los SAN son los más completos y potentes, pero son mucho más complejos y caros por lo que solo los aconsejamos en entornos que requieran de una gran exigencia.\n",
        "\n",
        "<h1><center>EJERCICIO</center></h1>\n"
      ],
      "metadata": {
        "id": "Q58uV2JcQL9a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWT1yCq9Q_dX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}